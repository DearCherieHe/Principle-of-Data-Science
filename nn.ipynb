{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import NuSVR, SVR\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/cheriehe/OneDrive - Business/kaggle202/earthquake prediction\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/cheriehe/OneDrive - Business/kaggle202\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_test_X=pd.read_csv('scale_test_features_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Hann_window_mean_150</th>\n",
       "      <th>Hann_window_mean_1500</th>\n",
       "      <th>Hann_window_mean_15000</th>\n",
       "      <th>Hann_window_mean_50</th>\n",
       "      <th>Hilbert_mean</th>\n",
       "      <th>abs_max</th>\n",
       "      <th>abs_max_roll_mean_10</th>\n",
       "      <th>abs_max_roll_mean_100</th>\n",
       "      <th>abs_max_roll_mean_1000</th>\n",
       "      <th>...</th>\n",
       "      <th>std_roll_std_10000</th>\n",
       "      <th>std_roll_std_50</th>\n",
       "      <th>std_roll_std_500</th>\n",
       "      <th>sum</th>\n",
       "      <th>time_rev_asym_stat_1</th>\n",
       "      <th>time_rev_asym_stat_10</th>\n",
       "      <th>time_rev_asym_stat_100</th>\n",
       "      <th>time_rev_asym_stat_5</th>\n",
       "      <th>time_rev_asym_stat_50</th>\n",
       "      <th>trend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.706720</td>\n",
       "      <td>0.706511</td>\n",
       "      <td>0.707966</td>\n",
       "      <td>0.706740</td>\n",
       "      <td>0.042268</td>\n",
       "      <td>0.012960</td>\n",
       "      <td>0.013842</td>\n",
       "      <td>0.006158</td>\n",
       "      <td>0.013459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008027</td>\n",
       "      <td>0.013292</td>\n",
       "      <td>0.012711</td>\n",
       "      <td>0.706678</td>\n",
       "      <td>0.554595</td>\n",
       "      <td>0.649700</td>\n",
       "      <td>0.618910</td>\n",
       "      <td>0.548292</td>\n",
       "      <td>0.256051</td>\n",
       "      <td>0.500608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.497303</td>\n",
       "      <td>0.497618</td>\n",
       "      <td>0.498812</td>\n",
       "      <td>0.497252</td>\n",
       "      <td>0.045164</td>\n",
       "      <td>0.018472</td>\n",
       "      <td>0.015254</td>\n",
       "      <td>0.007911</td>\n",
       "      <td>0.008635</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013158</td>\n",
       "      <td>0.021184</td>\n",
       "      <td>0.020651</td>\n",
       "      <td>0.497219</td>\n",
       "      <td>0.554611</td>\n",
       "      <td>0.649709</td>\n",
       "      <td>0.618912</td>\n",
       "      <td>0.548306</td>\n",
       "      <td>0.256061</td>\n",
       "      <td>0.679936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.784127</td>\n",
       "      <td>0.784395</td>\n",
       "      <td>0.786238</td>\n",
       "      <td>0.784101</td>\n",
       "      <td>0.052868</td>\n",
       "      <td>0.032772</td>\n",
       "      <td>0.035384</td>\n",
       "      <td>0.016449</td>\n",
       "      <td>0.020794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023339</td>\n",
       "      <td>0.029346</td>\n",
       "      <td>0.028924</td>\n",
       "      <td>0.784078</td>\n",
       "      <td>0.554633</td>\n",
       "      <td>0.649722</td>\n",
       "      <td>0.618909</td>\n",
       "      <td>0.548330</td>\n",
       "      <td>0.256051</td>\n",
       "      <td>0.548720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.732647</td>\n",
       "      <td>0.732740</td>\n",
       "      <td>0.734171</td>\n",
       "      <td>0.732616</td>\n",
       "      <td>0.028412</td>\n",
       "      <td>0.009683</td>\n",
       "      <td>0.008434</td>\n",
       "      <td>0.004689</td>\n",
       "      <td>0.012972</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006785</td>\n",
       "      <td>0.010980</td>\n",
       "      <td>0.010774</td>\n",
       "      <td>0.732609</td>\n",
       "      <td>0.554597</td>\n",
       "      <td>0.649699</td>\n",
       "      <td>0.618917</td>\n",
       "      <td>0.548292</td>\n",
       "      <td>0.256050</td>\n",
       "      <td>0.505784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.469226</td>\n",
       "      <td>0.468777</td>\n",
       "      <td>0.465227</td>\n",
       "      <td>0.469259</td>\n",
       "      <td>0.040391</td>\n",
       "      <td>0.022196</td>\n",
       "      <td>0.016794</td>\n",
       "      <td>0.010551</td>\n",
       "      <td>0.008814</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015242</td>\n",
       "      <td>0.021200</td>\n",
       "      <td>0.020740</td>\n",
       "      <td>0.469250</td>\n",
       "      <td>0.554580</td>\n",
       "      <td>0.649706</td>\n",
       "      <td>0.618924</td>\n",
       "      <td>0.548285</td>\n",
       "      <td>0.256051</td>\n",
       "      <td>0.396607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 828 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Hann_window_mean_150  Hann_window_mean_1500  \\\n",
       "0           0              0.706720               0.706511   \n",
       "1           1              0.497303               0.497618   \n",
       "2           2              0.784127               0.784395   \n",
       "3           3              0.732647               0.732740   \n",
       "4           4              0.469226               0.468777   \n",
       "\n",
       "   Hann_window_mean_15000  Hann_window_mean_50  Hilbert_mean   abs_max  \\\n",
       "0                0.707966             0.706740      0.042268  0.012960   \n",
       "1                0.498812             0.497252      0.045164  0.018472   \n",
       "2                0.786238             0.784101      0.052868  0.032772   \n",
       "3                0.734171             0.732616      0.028412  0.009683   \n",
       "4                0.465227             0.469259      0.040391  0.022196   \n",
       "\n",
       "   abs_max_roll_mean_10  abs_max_roll_mean_100  abs_max_roll_mean_1000  ...  \\\n",
       "0              0.013842               0.006158                0.013459  ...   \n",
       "1              0.015254               0.007911                0.008635  ...   \n",
       "2              0.035384               0.016449                0.020794  ...   \n",
       "3              0.008434               0.004689                0.012972  ...   \n",
       "4              0.016794               0.010551                0.008814  ...   \n",
       "\n",
       "   std_roll_std_10000  std_roll_std_50  std_roll_std_500       sum  \\\n",
       "0            0.008027         0.013292          0.012711  0.706678   \n",
       "1            0.013158         0.021184          0.020651  0.497219   \n",
       "2            0.023339         0.029346          0.028924  0.784078   \n",
       "3            0.006785         0.010980          0.010774  0.732609   \n",
       "4            0.015242         0.021200          0.020740  0.469250   \n",
       "\n",
       "   time_rev_asym_stat_1  time_rev_asym_stat_10  time_rev_asym_stat_100  \\\n",
       "0              0.554595               0.649700                0.618910   \n",
       "1              0.554611               0.649709                0.618912   \n",
       "2              0.554633               0.649722                0.618909   \n",
       "3              0.554597               0.649699                0.618917   \n",
       "4              0.554580               0.649706                0.618924   \n",
       "\n",
       "   time_rev_asym_stat_5  time_rev_asym_stat_50     trend  \n",
       "0              0.548292               0.256051  0.500608  \n",
       "1              0.548306               0.256061  0.679936  \n",
       "2              0.548330               0.256051  0.548720  \n",
       "3              0.548292               0.256050  0.505784  \n",
       "4              0.548285               0.256051  0.396607  \n",
       "\n",
       "[5 rows x 828 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_test_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Hann_window_mean_150', 'Hann_window_mean_1500',\n",
       "       'Hann_window_mean_15000', 'Hann_window_mean_50', 'Hilbert_mean',\n",
       "       'abs_max', 'abs_max_roll_mean_10', 'abs_max_roll_mean_100',\n",
       "       'abs_max_roll_mean_1000',\n",
       "       ...\n",
       "       'std_roll_std_10000', 'std_roll_std_50', 'std_roll_std_500', 'sum',\n",
       "       'time_rev_asym_stat_1', 'time_rev_asym_stat_10',\n",
       "       'time_rev_asym_stat_100', 'time_rev_asym_stat_5',\n",
       "       'time_rev_asym_stat_50', 'trend'],\n",
       "      dtype='object', length=828)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_test_X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_test_X.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2624, 827)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_train_X=pd.read_csv('scale_train_features_new.csv')\n",
    "train_y=pd.read_csv('y_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_train_X.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4195, 827)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4195, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_flatten=train_y.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaled1, x_test_scaled1, y_train1, y_test1 = train_test_split(scaled_train_X, train_y, test_size = 0.2, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_flatten1 = y_train1.values.ravel() #flattening the y_train\n",
    "y_test_flatten1 = y_test1.values.ravel() #flattening the y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3356, 827)\n",
      "(839, 827)\n",
      "(3356,)\n",
      "(839,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_scaled1.shape)\n",
    "print(x_test_scaled1.shape)\n",
    "print(y_train_flatten1.shape)\n",
    "print(y_test_flatten1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. BLOCK1: ((DENSE(512 filters) ---> ACTIVATION ---> BN) x 2) -----> DROPOUT\n",
    "\n",
    "#2. BLOCK1: ((DENSE(32 filters) ---> ACTIVATION ---> BN) x 2) -----> DROPOUT\n",
    "\n",
    "#3. BLOCK2 : ((DENSE(32 filters) ---> ACTIVATION ---> BN) x 2) -----> DROPOUT\n",
    "\n",
    "#4. BLOCK3: ((DENSE(32 filters) ---> ACTIVATION ---> BN) x 2) -----> DROPOUT\n",
    "\n",
    "#5. BLOCK4(output layer): (DENSE(classes) ---> ACTIVATION 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_init = 'he_normal'\n",
    "def Model(input_dim, activation, classes):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(512, kernel_initializer = kernel_init, input_dim = input_dim))\n",
    "    model.add(Activation(activation))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(32, kernel_initializer = kernel_init, input_dim = input_dim))\n",
    "    model.add(Activation(activation))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Dense(32, kernel_initializer = kernel_init)) \n",
    "    model.add(Activation(activation))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(32, kernel_initializer = kernel_init)) \n",
    "    model.add(Activation(activation))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.01))\n",
    "\n",
    "    model.add(Dense(32, kernel_initializer = kernel_init))    \n",
    "    model.add(Activation(activation))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(32, kernel_initializer = kernel_init))    \n",
    "    model.add(Activation(activation))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.001))\n",
    "    \n",
    "    model.add(Dense(32, kernel_initializer = kernel_init))    \n",
    "    model.add(Activation(activation))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(32, kernel_initializer = kernel_init))    \n",
    "    model.add(Activation(activation))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.0001))\n",
    "\n",
    "    model.add(Dense(classes, kernel_initializer = kernel_init))    \n",
    "    model.add(Activation('linear'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/cheriehe/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/cheriehe/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "input_dim = scaled_train_X.shape[1]\n",
    "activation = 'tanh'\n",
    "classes = 1 #the output labels\n",
    "model = Model(input_dim = input_dim, activation = activation, classes = classes)\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = optimizers.Adam(lr = 0.001, decay = 0.001 / 32)\n",
    "model.compile(loss = 'mean_absolute_error', optimizer = optim, metrics = ['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/cheriehe/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "mae_list=[]\n",
    "import sys\n",
    "for i in range(1,12):\n",
    "    sys.stdout = open('keras_output6.txt', 'a')\n",
    "    h= model.fit(x_train_scaled1, y_train_flatten1, epochs = i, batch_size = 32, verbose = 1)\n",
    "    sys.stdout = sys.__stdout__\n",
    "    predictions = model.predict(x_test_scaled1, verbose = 1, batch_size = 32) #make predictons on the test data \n",
    "    mae = mean_absolute_error(predictions, y_test_flatten1) \n",
    "    mae_list.append(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.544098884881387,\n",
       " 2.874447800960509,\n",
       " 2.718986084662533,\n",
       " 2.8541202856867876,\n",
       " 3.120365549479137,\n",
       " 2.7601288877080226,\n",
       " 2.8476649035439,\n",
       " 2.4211986714801785,\n",
       " 3.107544913320667,\n",
       " 2.42965324644907,\n",
       " 2.955813910506325]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# epochs, batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = scaled_test_X.shape[1]\n",
    "activation = 'tanh'\n",
    "classes = 1\n",
    "\n",
    "history = dict() #dictionery to store the history of individual models for later visualization\n",
    "prediction_scores = dict() #dictionery to store the predicted scores of individual models on the test dataset\n",
    "\n",
    "#here we will be training the same model for a total of 10 times and will be considering the mean of the output values for predictions\n",
    "for i in np.arange(0, 15):\n",
    "    optim = optimizers.Adam(lr = 0.001, decay = 0.001 / 32)\n",
    "    ensemble_model = Model(input_dim = input_dim, activation = activation, classes = classes)\n",
    "    ensemble_model.compile(loss = 'mean_absolute_error', optimizer = optim, metrics = ['mean_absolute_error'])\n",
    "    print('TRAINING MODEL NO : {}'.format(i))\n",
    "    sys.stdout = open('keras_output7.txt', 'w')\n",
    "    H = ensemble_model.fit(scaled_train_X, y_train_flatten,\n",
    "                  batch_size = 32,\n",
    "                  epochs = 11,\n",
    "                  verbose = 1)\n",
    "    sys.stdout = sys.__stdout__\n",
    "    history[i] = H\n",
    "    \n",
    "#     ensemble_model.save('MODEL_{}.model'.format(i))\n",
    "    \n",
    "    predictions = ensemble_model.predict(scaled_test_X, verbose = 1, batch_size = 32)\n",
    "    prediction_scores[i] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making predictions\n",
    "prediction1 = np.hstack([p.reshape(-1,1) for p in prediction_scores.values()]) #taking the scores of all the trained models\n",
    "prediction1 = np.mean(prediction1, axis = 1)\n",
    "\n",
    "print(prediction1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, ..., nan, nan, nan], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submitting the file\n",
    "submission = pd.read_csv('sample_submission.csv', index_col = 'seg_id')\n",
    "submission['time_to_failure'] = prediction1\n",
    "submission.to_csv('submission_nn3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
